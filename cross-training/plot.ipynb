{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aba35-5906-4f8d-bbef-d574bff032e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"/proj/gaia-climate/team/kirill/gaia-surrogate\")\n",
    "from gaia.training import load_hparams_file, get_dataset_from_model, get_checkpoint_file, get_levels\n",
    "from gaia.data import unflatten_tensor, flatten_tensor\n",
    "from gaia.config import levels\n",
    "from gaia.plot import lats, lons, get_land_outline\n",
    "from gaia.models import TrainingModel\n",
    "import tqdm.auto as tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4543e1f-554c-4ca7-ac44-70abf92410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = torch.tensor([l if l<=180 else l-360 for l in lons])\n",
    "lon_vals,lon_idx =  lons.sort() \n",
    "lons = lon_vals.tolist()\n",
    "outline = get_land_outline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b5e3e-3f0c-4682-a984-4417079099b9",
   "metadata": {},
   "source": [
    "## model evaluated on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf3f0d-20cc-4594-b2dc-0400d4361736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y,yhat,reduce_dims = [0,3], y2  = None):\n",
    "    mse = (y-yhat).square().mean(dim = reduce_dims)\n",
    "\n",
    "    if y2 is None:\n",
    "        var = y.var(reduce_dims, unbiased = False)\n",
    "    else:\n",
    "        var = y2.var(reduce_dims, unbiased = False)\n",
    "\n",
    "    skill = (1 - mse/var).clip(min = 0)\n",
    "    return dict(rmse = mse.sqrt(), std = var.sqrt(), skill = skill) \n",
    "\n",
    "\n",
    "    \n",
    "# mse, var, skill = get_2d_metrics(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc469f9a-25ae-4a11-9d55-94ba97e6ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_cmap = \"dimgray\"\n",
    "def plot_levels_vs_lats(x,z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = skill_cmap\n",
    "    else:\n",
    "        cmap = \"fire\"\n",
    "        \n",
    "    width = 350\n",
    "    height = 300\n",
    "        \n",
    "    return hv.QuadMesh((lats, levels[\"spcam\"], x),[\"lats\",\"levels\"],[z_name]).opts(invert_yaxis = True, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "def plot_lats_vs_lons(x, z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = skill_cmap\n",
    "    else:\n",
    "        cmap = \"fire\"\n",
    "\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "\n",
    "    x = x[:,lon_idx]\n",
    "        \n",
    "    return hv.QuadMesh((lons, lats, x),[\"lons\",\"lats\"],[z_name]).opts(invert_yaxis = False, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "\n",
    "def plot_lats_vs_metric(x, z_name):\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "        \n",
    "    return hv.Curve((lats, x),[\"lats\"],[z_name]).opts( tools = [\"hover\"],  width = width, height = height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a505aaa-7237-4c41-9261-2febb99acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e81bef-8255-42bd-88a2-2ca0dad8f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(targets, predictions, output_index, true_predictions = None):\n",
    "    ### make lats vs level plots for 2d vars\n",
    "    \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0,3], y2 = true_predictions)\n",
    "    \n",
    "    plots = OrderedDict()\n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s > 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "                temp  = plot_levels_vs_lats(metric_value[s:e],f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "                \n",
    "                \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0],y2 = true_predictions)\n",
    "\n",
    "    \n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s == 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "\n",
    "                temp = plot_lats_vs_lons(metric_value[s:e].squeeze(), f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "    \n",
    "\n",
    "    \n",
    "    return plots\n",
    "\n",
    "def compute_metrics(targets, predictions, output_index, true_predictions = None):\n",
    "\n",
    "    # metric_dict = get_metrics(targets, predictions, reduce_dims = [0],y2 = true_predictions)\n",
    "\n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0,2,3],y2 = true_predictions)\n",
    "\n",
    "    metric_dict[\"variable\"]  = [f\"{k}_{l:02}\" if e-s>1 else k for k,(s,e) in output_index.items() for l in range(e-s)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for k,v in output_index.items():\n",
    "    #     s,e = v\n",
    "        \n",
    "    #     # if k == \"PTEQ\":\n",
    "    #     #     s = s+8 #ignore top levels\n",
    "        \n",
    "    #     metric_dict = get_metrics(targets[:,s:e,...], predictions[:,s:e,...], reduce_dims = [0,1,2,3],y2 = true_predictions[:,s:e,...] if true_predictions is not None else None)\n",
    "    #     metric_dict[\"variable\"] = k\n",
    "    #     metrics_out.append(metric_dict)\n",
    "        \n",
    "    return metric_dict\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82067d-f513-4f24-abd7-5b3e5dd3b190",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate models trained on [cam4, spcam] on [cam4 ,spcam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187655b-51a1-4ebb-8696-5f7416f3dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for model_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "        \n",
    "\n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_{model_name}\"\n",
    "        dataset = f\"{dataset_name}_paper\" if \"cam4\" in dataset_name else f\"{dataset_name}_fixed\"\n",
    "\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset )\n",
    "        targets =  unflatten_tensor(test_dataset[\"y\"])\n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474b7f6-3126-43c2-bf7c-975875b60c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d09b10-94eb-43f1-9cdc-a28bf8c6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10c4bd-8737-4597-a4c5-d9254d3a1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.themes import built_in_themes\n",
    "print(built_in_themes.keys())\n",
    "hv.renderer('bokeh').theme = built_in_themes['dark_minimal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b53f5-bad8-4b84-80e4-dad4b153fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ceae3-70c1-424f-9d0f-985ef7197608",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "import numpy as np\n",
    "# for cmap in [\"bgyw\",\"dimgray\",\"bmy\",\"fire\"]:\n",
    "for cmap in [\"bgyw\"]:\n",
    "    colorbar = True\n",
    "    temp = hv.HoloMap(OrderedDict({k[:-1]:v.opts(ylabel=\"pressure\", width = 420) for k,v in all_plots.items() if \"PREC\" not in k[2] and k[3] == \"skill\"}),sort = False, kdims = [\"model\",\"dataset\",\"variable\"])\n",
    "    for v in [\"PTTEND\",\"PTEQ\"]:\n",
    "        temp1 = temp[:,:,v].layout([\"model\",\"dataset\"]).cols(2).opts(hv.opts.QuadMesh(cmap = cmap, colorbar=False))\n",
    "        hv.save(temp1,f\"levels_vs_lats_{v}_{cmap}.html\")\n",
    "    hv.save(hv.Image(np.array([[0,1.],[0,1.]])).opts(colorbar = True,cmap = cmap), f\"colorbar_{cmap}.html\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8653b7-9de2-4bbd-bfaf-c0e4876ced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp2 = temp.select(model=\"cam4\",variable=\"PTEQ\")\n",
    "# from bokeh.io import export_png\n",
    "# export_png(temp2,filename = \"temp1.png\")\n",
    "# hv.save(temp2,\"temp2.png\")\n",
    "# temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc515285-cfe5-4a27-9155-1997009a6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R /home/kirill.trapeznikov/chromedriver_path/chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8b1b8-5017-441d-aaac-6a3abd97cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "for cmap in [\"bgyw\",\"dimgray\",\"bmy\",\"fire\"]:\n",
    "    temp = hv.HoloMap(OrderedDict({k[:-1]:v.opts(colorbar=False) for k,v in all_plots.items() if \"PRECT\" in k[2] and k[3] == \"skill\"}),sort = False, kdims = [\"model\",\"dataset\",\"variable\"])\n",
    "    temp = (temp*outline.opts(line_color = \"black\", line_width = 1)).layout([\"model\",\"dataset\"]).cols(2)\n",
    "    temp = temp.opts(hv.opts.QuadMesh(cmap = cmap))\n",
    "    hv.save(temp,f\"lons_vs_lats_{cmap}.html\")\n",
    "# temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ab881-0dfc-47d2-9979-28c9b2e4c055",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### compute top level performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a163d5e-2c41-43fe-8ddc-2fc88dfdd37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_metrics = []\n",
    "\n",
    "for model_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "        \n",
    "\n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_{model_name}\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset )\n",
    "        targets =  unflatten_tensor(test_dataset[\"y\"])\n",
    "        plots = compute_metrics(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        plots = pd.DataFrame(plots)\n",
    "        plots[\"model_name\"] = model_name\n",
    "        plots[\"dataset_name\"] = dataset_name\n",
    "        all_metrics.append(plots)\n",
    "\n",
    "all_metrics = pd.concat(all_metrics, ignore_index=True)\n",
    "# all_metrics.to_csv(\"benchmarks.csv\")\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176583d7-5138-4f55-8789-7547922a74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22d441-91fb-478a-acb8-31140eef68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[\"variable_top\"] = all_metrics.variable.apply(lambda a: a.split(\"_\")[0])\n",
    "all_metrics[\"level_number\"] = all_metrics.variable.apply(lambda a: a.split(\"_\")[-1])\n",
    "all_metrics[\"level\"] = all_metrics.level_number.apply(lambda a: levels[\"spcam\"][int(a)] if a.isnumeric() else None)\n",
    "all_metrics.columns = [c.split(\"_\")[0] for c in all_metrics.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae86bff-48b2-4893-a5c7-b1eee9a2f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_metrics.iloc[:,[0,1,2,4,5,6,8]]\n",
    "temp = temp.loc[~temp.variable.str.startswith(\"PREC\")]\n",
    "temp.to_csv(\"benchmark_levels_vs_metrics.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf5c4f-d72e-427b-9360-1e11626be603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def temp_func(model, dataset,variable):\n",
    "#     hv.Curve(temp.query(f\"model=='{model}' & dataset =='{dataset}' & variable =='{variable}'\"),[\"level\"],[\"skill\"])*\\\n",
    "#     hv.Curve(temp.query(f\"model=='{model}' & dataset =='{dataset}' & variable =='{variable}'\"),[\"level\"],[\"skill\"])\n",
    "    \n",
    "# hv.DynamicMap(lambda  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2f341-4477-4da4-99c4-d7b9181d193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "hv.extension(\"bokeh\")\n",
    "data = pd.read_csv(\"benchmark_levels_vs_metrics.csv\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772bdb7d-4b0e-4ce1-be2e-b0e6d0b0aff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colors = {\"cam4\" : \"orange\",\n",
    "                \"spcam\": \"purple\"}\n",
    "\n",
    "def temp_func(model,dataset,variable):\n",
    "    data_subset = data.query(f\"model=='{model}' &  dataset=='{dataset}' &  variable=='{variable}'\")\n",
    "    line_dash = \"solid\" if model == dataset else \"dashed\"\n",
    "    return  (hv.Curve(data_subset,  [\"level\"],[\"skill\"], label = f\"{model} on {dataset}\" ).opts(color = model_colors[model], line_dash = line_dash, line_width = 1,show_grid = True) * \\\n",
    "             hv.Scatter(data_subset,[\"level\"],[\"skill\"]).opts(color = model_colors[model], line_dash = line_dash, size = 5))\n",
    "plots = []\n",
    "for v in [\"PTEQ\",\"PTTEND\"]:\n",
    "    for m in [\"cam4\",\"spcam\"]:\n",
    "        for d in [\"cam4\",\"spcam\"]:\n",
    "            plots.append(temp_func(m,d,v))\n",
    "\n",
    "plots = (hv.Overlay(plots[:4]).opts(width = 400,show_legend= False,title = \"PTEQ\") + hv.Overlay(plots[4:]).opts(width = 530,title = \"PTTEND\", legend_position=\"right\",legend_opts={\"title\":\"model on dataset\"}))\n",
    "hv.save(plots,\"level_vs_skill.html\")\n",
    "plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46224263-6fd2-4b6a-b68b-afd30125310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"color_field\"] = data.model.apply(lambda a: \"blue\" if a == \"cam4\" else \"orange\")\n",
    "data[\"line_field\"] =  data.dataset.apply(lambda a: [0,1] if a == \"cam4\" else [1,1])\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd5a07-9cde-4452-9221-f679f7a56ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"line_field\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a154498e-23b3-4406-b03d-fbd014fc42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hvplot.line(x  = \"level\", y = \"skill\", by = [\"model\",\"dataset\"], line_width = 1, color = \"color_field\",  groupby = [\"variable\"], grid = True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a1105-fefa-401d-bc49-8e4a90fb8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = all_metrics.applymap(lambda a: a.item() if torch.is_tensor(a) else a)\n",
    "all_metrics.to_csv(\"benchmarks.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfaf46-1232-4f81-b28d-dd14edacae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_metrics.to_markdown(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027ae73-d584-404c-931c-9fddd4f743b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compare predictions of cam4 and spcam trained models on either cam4 inputs and spcam inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fdf8e-fd09-4ef0-be70-e1fa6d4d5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_cam4\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        targets = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_spcam\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        model_name = \"cam4_vs_spcam\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "            \n",
    "        plots = make_plots(predictions, targets, model.hparams.output_index)\n",
    "        \n",
    "        model_name = \"spcam_vs_cam4\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee628a-e214-429a-a3c0-87040d195c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" not in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"levels_vs_lats_cross.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f1049-a4cc-46a8-8f85-d8eb60544f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = (temp*outline.opts(color = \"black\", line_width = 1).layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"lons_vs_lats_cross.html\")\n",
    "temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de059e73",
   "metadata": {},
   "source": [
    "### Normalize by the Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "dataset_temp = {}\n",
    "\n",
    "for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_cam4\"\n",
    "        dataset = f\"{dataset_name}_paper\" if \"cam4\" in dataset_name else f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        targets = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        if dataset_name in model_dir:\n",
    "              test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset_name )\n",
    "              true_predictions =  unflatten_tensor(test_dataset[\"y\"])\n",
    "              dataset_temp[dataset_name] = true_predictions\n",
    "        \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_spcam\"\n",
    "        dataset = f\"{dataset_name}_paper\" if \"cam4\" in dataset_name else f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "\n",
    "        if dataset_name in model_dir:\n",
    "              test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset_name )\n",
    "              true_predictions =  unflatten_tensor(test_dataset[\"y\"])\n",
    "       \n",
    "        \n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index, true_predictions=true_predictions)\n",
    "        \n",
    "        model_name = \"cam4_vs_spcam\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "            \n",
    "        # plots = make_plots(predictions, targets, model.hparams.output_index)\n",
    "        \n",
    "        # model_name = \"spcam_vs_cam4_on_spcam\"\n",
    "        \n",
    "        # for k,v in plots.items():\n",
    "        #     new_key = (model_name, dataset_name) + k\n",
    "        #     all_plots[new_key] = v\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc829e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "for cmap in [\"bgyw\",\"dimgray\",\"bmy\",\"fire\"]:\n",
    "\n",
    "    temp = hv.HoloMap(OrderedDict({k[:-1]:v.opts(colorbar=False,ylabel = \"pressure\",width = 420) for k,v in all_plots.items() if \"PREC\" not in k[2] and k[3]==\"skill\"}),sort = False, kdims = [\"model\",\"dataset\",\"variable\"])\n",
    "\n",
    "    temp = temp.layout([\"model\",\"dataset\",\"model\"]).cols(4)\n",
    "    temp = temp.opts(hv.opts.QuadMesh(cmap = cmap, colorbar=False))\n",
    "\n",
    "    hv.save(temp1,f\"levels_vs_lats_cross_norm_truth_{cmap}.html\")\n",
    "    # temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "for cmap in [\"bgyw\",\"dimgray\",\"bmy\",\"fire\"]:\n",
    "\n",
    "    temp = hv.HoloMap(OrderedDict({k[:-1]:v.opts(colorbar=False) for k,v in all_plots.items() if \"PRECT\" in k[2] and k[3]==\"skill\"}),sort = False, kdims = [\"model\",\"dataset\",\"variable\"])\n",
    "    temp = (temp*outline.opts(color = \"black\", line_width = 1)).layout([\"model\",\"dataset\"]).cols(2)\n",
    "    temp = temp.opts(hv.opts.QuadMesh(cmap = cmap, colorbar=False))\n",
    "\n",
    "    hv.save(temp,f\"lons_vs_lats_cross_norm_truth_{cmap}.html\")\n",
    "    temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fe91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset size\n",
    "import glob\n",
    "for f in glob.glob(\"/ssddg1/gaia/fixed/*.pt\"):\n",
    "    print(f)\n",
    "    temp = torch.load(f)\n",
    "    if \"x\" in temp:\n",
    "        print(temp[\"x\"].shape)\n",
    "    if \"y\" in temp:\n",
    "        print(temp[\"y\"].shape)\n",
    "\n",
    "\n",
    "\n",
    "# torch.load(\"/ssddg1/gaia/fixed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save comparison plots\n",
    "\n",
    "out = []\n",
    "\n",
    "for model_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_{model_name}\"\n",
    "        dataset = f\"{dataset_name}_paper\" if \"cam4\" in dataset_name else f\"{dataset_name}_fixed\"\n",
    "        out.append(pd.read_json(f\"{model_dir}/test_results_{dataset}.json\"))\n",
    "        out[-1][\"model\"] = model_name\n",
    "        out[-1][\"dataset\"] = dataset_name\n",
    "        \n",
    "out = pd.concat(out,ignore_index=True)\n",
    "out.T.iloc[::-1].to_csv(\"top_level_performance.csv\")\n",
    "print(out.T.iloc[::-1].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadde585-c9c3-4748-b2bd-ddde0f72e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"x\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praxis",
   "language": "python",
   "name": "praxis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
