{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aba35-5906-4f8d-bbef-d574bff032e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"/proj/gaia-climate/team/kirill/gaia-surrogate\")\n",
    "from gaia.training import load_hparams_file, get_dataset_from_model, get_checkpoint_file, get_levels\n",
    "from gaia.data import unflatten_tensor, flatten_tensor\n",
    "from gaia.config import levels\n",
    "from gaia.plot import lats, lons, get_land_outline\n",
    "from gaia.models import TrainingModel\n",
    "import tqdm.auto as tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4543e1f-554c-4ca7-ac44-70abf92410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = torch.tensor([l if l<=180 else l-360 for l in lons])\n",
    "lon_vals,lon_idx =  lons.sort() \n",
    "lons = lon_vals.tolist()\n",
    "outline = get_land_outline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b5e3e-3f0c-4682-a984-4417079099b9",
   "metadata": {},
   "source": [
    "## model evaluated on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf3f0d-20cc-4594-b2dc-0400d4361736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y,yhat,reduce_dims = [0,3], y2  = None):\n",
    "    mse = (y-yhat).square().mean(dim = reduce_dims)\n",
    "\n",
    "    if y2 is None:\n",
    "        var = y.var(reduce_dims, unbiased = False)\n",
    "    else:\n",
    "        var = y2.var(reduce_dims, unbiased = False)\n",
    "\n",
    "    skill = (1 - mse/var).clip(min = 0)\n",
    "    return dict(rmse = mse.sqrt(), std = var.sqrt(), skill = skill) \n",
    "\n",
    "\n",
    "    \n",
    "# mse, var, skill = get_2d_metrics(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc469f9a-25ae-4a11-9d55-94ba97e6ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_levels_vs_lats(x,z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = \"Greens\"\n",
    "    else:\n",
    "        cmap = \"Oranges\"\n",
    "        \n",
    "    width = 350\n",
    "    height = 300\n",
    "        \n",
    "    return hv.QuadMesh((lats, levels[\"spcam\"], x),[\"lats\",\"levels\"],[z_name]).opts(invert_yaxis = True, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "def plot_lats_vs_lons(x, z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = \"Greens\"\n",
    "    else:\n",
    "        cmap = \"Oranges\"\n",
    "\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "\n",
    "    x = x[:,lon_idx]\n",
    "        \n",
    "    return hv.QuadMesh((lons, lats, x),[\"lons\",\"lats\"],[z_name]).opts(invert_yaxis = False, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "\n",
    "def plot_lats_vs_metric(x, z_name):\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "        \n",
    "    return hv.Curve((lats, x),[\"lats\"],[z_name]).opts( tools = [\"hover\"],  width = width, height = height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a505aaa-7237-4c41-9261-2febb99acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e81bef-8255-42bd-88a2-2ca0dad8f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(targets, predictions, output_index, true_predictions = None):\n",
    "    ### make lats vs level plots for 2d vars\n",
    "    \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0,3], y2 = true_predictions)\n",
    "    \n",
    "    plots = OrderedDict()\n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s > 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "                temp  = plot_levels_vs_lats(metric_value[s:e],f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "                \n",
    "                \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0],y2 = true_predictions)\n",
    "\n",
    "    \n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s == 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "\n",
    "                temp = plot_lats_vs_lons(metric_value[s:e].squeeze(), f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "    \n",
    "\n",
    "    \n",
    "    return plots\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82067d-f513-4f24-abd7-5b3e5dd3b190",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate models trained on [cam4, spcam] on [cam4 ,spcam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187655b-51a1-4ebb-8696-5f7416f3dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for model_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "        \n",
    "\n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_{model_name}\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset )\n",
    "        targets =  unflatten_tensor(test_dataset[\"y\"])\n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d09b10-94eb-43f1-9cdc-a28bf8c6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10c4bd-8737-4597-a4c5-d9254d3a1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.themes import built_in_themes\n",
    "print(built_in_themes.keys())\n",
    "hv.renderer('bokeh').theme = built_in_themes['dark_minimal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b53f5-bad8-4b84-80e4-dad4b153fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ceae3-70c1-424f-9d0f-985ef7197608",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" not in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"levels_vs_lats.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8b1b8-5017-441d-aaac-6a3abd97cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = (temp*outline.opts(color = \"black\", line_width = 1)).layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"lons_vs_lats.html\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbc416-b4d6-4ea0-b150-cac4124c12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.save(temp,\"lons_vs_lats.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027ae73-d584-404c-931c-9fddd4f743b1",
   "metadata": {},
   "source": [
    "### Compare predictions of cam4 and spcam trained models on either cam4 inputs and spcam inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fdf8e-fd09-4ef0-be70-e1fa6d4d5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_cam4\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        targets = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_spcam\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        model_name = \"cam4_vs_spcam\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "            \n",
    "        plots = make_plots(predictions, targets, model.hparams.output_index)\n",
    "        \n",
    "        model_name = \"spcam_vs_cam4\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee628a-e214-429a-a3c0-87040d195c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" not in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"levels_vs_lats_cross.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f1049-a4cc-46a8-8f85-d8eb60544f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = (temp*outline.opts(color = \"black\", line_width = 1).layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"lons_vs_lats_cross.html\")\n",
    "temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de059e73",
   "metadata": {},
   "source": [
    "### Normalize by the Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2261ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_cam4\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        targets = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        \n",
    "        if dataset_name in model_dir:\n",
    "              test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset_name )\n",
    "              true_predictions =  unflatten_tensor(test_dataset[\"y\"])\n",
    "        \n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_spcam\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        \n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "\n",
    "        if dataset_name in model_dir:\n",
    "              test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset_name )\n",
    "              true_predictions =  unflatten_tensor(test_dataset[\"y\"])\n",
    "       \n",
    "        \n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index, true_predictions=true_predictions)\n",
    "        \n",
    "        model_name = \"cam4_vs_spcam\"\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "            \n",
    "        # plots = make_plots(predictions, targets, model.hparams.output_index)\n",
    "        \n",
    "        # model_name = \"spcam_vs_cam4_on_spcam\"\n",
    "        \n",
    "        # for k,v in plots.items():\n",
    "        #     new_key = (model_name, dataset_name) + k\n",
    "        #     all_plots[new_key] = v\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc829e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" not in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"levels_vs_lats_cross_norm_truth.html\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = (temp*outline.opts(color = \"black\", line_width = 1)).layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"lons_vs_lats_cross_norm_truth.html\")\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fe91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataset size\n",
    "import glob\n",
    "for f in glob.glob(\"/ssddg1/gaia/fixed/*.pt\"):\n",
    "    print(f)\n",
    "    temp = torch.load(f)\n",
    "    if \"x\" in temp:\n",
    "        print(temp[\"x\"].shape)\n",
    "    if \"y\" in temp:\n",
    "        print(temp[\"y\"].shape)\n",
    "\n",
    "\n",
    "\n",
    "# torch.load(\"/ssddg1/gaia/fixed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5114c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[\"x\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praxis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
