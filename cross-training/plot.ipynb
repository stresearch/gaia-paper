{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aba35-5906-4f8d-bbef-d574bff032e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"/proj/gaia-climate/team/kirill/gaia-surrogate\")\n",
    "from gaia.training import load_hparams_file, get_dataset_from_model, get_checkpoint_file, get_levels\n",
    "from gaia.data import unflatten_tensor, flatten_tensor\n",
    "from gaia.config import levels\n",
    "from gaia.plot import lats, lons\n",
    "from gaia.models import TrainingModel\n",
    "import tqdm.auto as tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b5e3e-3f0c-4682-a984-4417079099b9",
   "metadata": {},
   "source": [
    "## model evaluated on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf3f0d-20cc-4594-b2dc-0400d4361736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y,yhat,reduce_dims = [0,3]):\n",
    "    mse = (y-yhat).square().mean(dim = reduce_dims)\n",
    "    var = y.var(reduce_dims, unbiased = False)\n",
    "    skill = (1 - mse/var).clip(min = 0)\n",
    "    return dict(rmse = mse.sqrt(), std = var.sqrt(), skill = skill) \n",
    "\n",
    "\n",
    "    \n",
    "# mse, var, skill = get_2d_metrics(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc469f9a-25ae-4a11-9d55-94ba97e6ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_levels_vs_lats(x,z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = \"Greens\"\n",
    "    else:\n",
    "        cmap = \"Oranges\"\n",
    "        \n",
    "    width = 350\n",
    "    height = 300\n",
    "        \n",
    "    return hv.QuadMesh((lats, levels[\"spcam\"], x),[\"lats\",\"levels\"],[z_name]).opts(invert_yaxis = True, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "def plot_lats_vs_lons(x, z_name):\n",
    "    if \"skill\" in z_name:\n",
    "        cmap = \"Greens\"\n",
    "    else:\n",
    "        cmap = \"Oranges\"\n",
    "\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "        \n",
    "    return hv.QuadMesh((lons, lats, x),[\"lons\",\"lats\"],[z_name]).opts(invert_yaxis = True, colorbar = True, tools = [\"hover\"], cmap = cmap, width = width, height = height)\n",
    "\n",
    "def plot_lats_vs_metric(x, z_name):\n",
    "        \n",
    "    width = 400\n",
    "    height = 300\n",
    "        \n",
    "    return hv.Curve((lats, x),[\"lats\"],[z_name]).opts( tools = [\"hover\"],  width = width, height = height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a505aaa-7237-4c41-9261-2febb99acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e81bef-8255-42bd-88a2-2ca0dad8f05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(targets, predictions, output_index):\n",
    "    ### make lats vs level plots for 2d vars\n",
    "    \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0,3])\n",
    "    \n",
    "    plots = OrderedDict()\n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s > 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "                temp  = plot_levels_vs_lats(metric_value[s:e],f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "                \n",
    "                \n",
    "    metric_dict = get_metrics(targets, predictions, reduce_dims = [0])\n",
    "\n",
    "    \n",
    "    \n",
    "    for k,v in output_index.items():\n",
    "        s,e = v\n",
    "        if e-s == 1:\n",
    "            for metric_name, metric_value in metric_dict.items():\n",
    "                plot_title = f\"{metric_name}_{k}\"\n",
    "\n",
    "                temp = plot_lats_vs_lons(metric_value[s:e].squeeze(), f\"{k}_std_units\" if metric_name != \"skill\" else \"skill\")\n",
    "                plots[(k,metric_name)] = temp#.opts(title = plot_title)\n",
    "    \n",
    "\n",
    "    \n",
    "    return plots\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82067d-f513-4f24-abd7-5b3e5dd3b190",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate models trained on [cam4, spcam] on [cam4 ,spcam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187655b-51a1-4ebb-8696-5f7416f3dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plots = OrderedDict()\n",
    "\n",
    "for model_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "    for dataset_name in tqdm.tqdm([\"cam4\",\"spcam\"]):\n",
    "        \n",
    "\n",
    "        model_dir = f\"../fine-tune/lightning_logs/base_{model_name}\"\n",
    "        dataset = f\"{dataset_name}_fixed\"\n",
    "\n",
    "        model = TrainingModel.load_from_checkpoint(get_checkpoint_file(model_dir), map_location=\"cpu\").eval()\n",
    "        predictions = torch.load(model_dir+f\"/predictions_{dataset}.pt\")\n",
    "        test_dataset, test_loader  = get_dataset_from_model(model, dataset =dataset )\n",
    "        targets =  unflatten_tensor(test_dataset[\"y\"])\n",
    "        plots = make_plots(targets, predictions, model.hparams.output_index)\n",
    "        \n",
    "        for k,v in plots.items():\n",
    "            new_key = (model_name, dataset_name) + k\n",
    "            all_plots[new_key] = v\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d09b10-94eb-43f1-9cdc-a28bf8c6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10c4bd-8737-4597-a4c5-d9254d3a1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.themes import built_in_themes\n",
    "print(built_in_themes.keys())\n",
    "hv.renderer('bokeh').theme = built_in_themes['dark_minimal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b53f5-bad8-4b84-80e4-dad4b153fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ceae3-70c1-424f-9d0f-985ef7197608",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.renderer('bokeh').theme = 'caliber'\n",
    "\n",
    "\n",
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" not in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"levels_vs_lats.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f8b1b8-5017-441d-aaac-6a3abd97cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = hv.HoloMap(OrderedDict({k:v for k,v in all_plots.items() if \"PREC\" in k[2]}),sort = False, kdims = [\"model\",\"dataset\",\"variable\",\"metric\"])\n",
    "temp = temp.layout([\"model\",\"metric\"]).cols(3)\n",
    "hv.save(temp,\"lons_vs_lats.html\")\n",
    "temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praxis",
   "language": "python",
   "name": "praxis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
